# -*- coding: utf-8 -*-
"""MonoTrad.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kktsdvOQ5cWp9NNVkdLfobsa_9xwNO6d

# **Configurações**
"""

import yfinance as yf
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy import stats
from statsmodels.stats.diagnostic import acorr_ljungbox
import warnings
warnings.filterwarnings('ignore')

"""# **Coleta e preparação dos dados**"""

# Configurações estilo dos gráficos para melhor visualização
plt.style.use('seaborn-v0_8-darkgrid')
plt.rcParams['figure.dpi'] = 100
plt.rcParams['font.size'] = 10

# Download de dados históricos do Ibovespa desde 2010
ibov = yf.download("^BVSP", start="2010-01-01", end="2025-10-01", progress=False)

print(ibov.info())
# print(ibov.head())

# Calcular retornos logarítmicos (mais adequados para modelagem financeira)
ibov['Retornos'] = np.log(ibov['Close'] / ibov['Close'].shift(1))
ibov = ibov.dropna()
print(ibov.head())

# Visualizar a série temporal completa
#fig, axes = plt.subplots(2, 1, figsize=(15, 10))

# Gráfico 1: Preço de Fechamento
#axes[0].plot(ibov.index, ibov['Close'], linewidth=1.5, color='navy')
#axes[0].set_title('Série Temporal: Preço de Fechamento do Ibovespa', fontsize=14, fontweight='bold')
#axes[0].set_xlabel('Data', fontsize=12)
#axes[0].set_ylabel('Preço (pontos)', fontsize=12)
#axes[0].grid(alpha=0.3)

# Gráfico 2: Retornos Logarítmicos
#axes[1].plot(ibov.index, ibov['Retornos'], linewidth=0.8, color='darkred', alpha=0.7)
#axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1)
#axes[1].set_title('Série Temporal: Retornos Logarítmicos do Ibovespa', fontsize=14, fontweight='bold')
#axes[1].set_xlabel('Data', fontsize=12)
#axes[1].set_ylabel('Retorno', fontsize=12)
#axes[1].grid(alpha=0.3)

#plt.tight_layout()
#plt.show()

"""# **Teste de estacionariedade**"""

# Normaliza colunas e garante 'Close'
ibov.columns = [col[0] if isinstance(col, tuple) else col for col in ibov.columns]
if 'Close' not in ibov.columns:
    cands = [c for c in ibov.columns if 'close' in c.lower()]
    if cands: ibov.rename(columns={cands[0]: 'Close'}, inplace=True)
    else: raise KeyError("Coluna 'Close' não encontrada no DataFrame.")

# Returns e limpeza
if 'Retornos' not in ibov.columns:
    ibov['Retornos'] = np.log(ibov['Close'] / ibov['Close'].shift(1))
before = len(ibov)
ibov = ibov.dropna(subset=['Close', 'Retornos'])
removed = before - len(ibov)

# Headline informativo
fmt = "%d/%m/%Y"
print(
    f"[DATA] obs={len(ibov)} | removidas={removed} | período={ibov.index[0].strftime(fmt)}→{ibov.index[-1].strftime(fmt)}"
)

# Estatísticas rápidas dos retornos
ret = ibov['Retornos']
print(
    f"[RET] média={ret.mean():.6f} | desvio={ret.std():.6f} | min={ret.min():.6f} | max={ret.max():.6f} | vol_anual≈{(ret.std()*252**0.5):.4f}"
)

# ADF compacto (inclui crítico 5% e sugestão de d)
from statsmodels.tsa.stattools import adfuller
def adf_summary(series, label):
    stat, p, _, _, crit, _ = adfuller(series, autolag='AIC')
    status = "ESTACIONÁRIA" if p < 0.05 else "NÃO estacionária"
    hint = "d=0"
    print(f"[ADF] {label:>22} | stat={stat:.4f} | p={p:.4f} | crit5%={crit['5%']:.4f} | {status} | {hint}")

adf_summary(ibov['Close'],   "Preço de Fechamento")
adf_summary(ibov['Retornos'], "Retornos Logarítmicos")

# ACF/PACF (títulos com n obs)
import matplotlib.pyplot as plt
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

fig, axes = plt.subplots(2, 1, figsize=(15, 10))
plot_acf(ret, lags=40, alpha=0.05, ax=axes[0])
axes[0].set_title(f'ACF — Retornos do Ibovespa (n={len(ret)})', fontsize=14, fontweight='bold')
plot_pacf(ret, lags=40, alpha=0.05, ax=axes[1])
axes[1].set_title(f'PACF — Retornos do Ibovespa (n={len(ret)})', fontsize=14, fontweight='bold')
for ax in axes: ax.set_xlabel('Lags'); ax.grid(alpha=0.3)
plt.tight_layout(); plt.show()

"""# ***Divisão dos dados (treino e teste)***"""

# # Divisão treino/teste
# if 'Retornos' not in ibov.columns:
#     ibov['Retornos'] = np.log(ibov['Close'] / ibov['Close'].shift(1))
# ibov = ibov.dropna(subset=['Retornos'])

# split_ratio = 0.8
# n = len(ibov)
# cut = int(n * split_ratio)
# train, test = ibov['Retornos'].iloc[:cut], ibov['Retornos'].iloc[cut:]

# fmt = "%d/%m/%Y"
# print(f"[SPLIT] Divisão temporal 80/20 concluída")
# print(f"  • Treino: {len(train)} obs ({split_ratio*100:.1f}%) — {train.index[0].strftime(fmt)} → {train.index[-1].strftime(fmt)}")
# print(f"  • Teste:  {len(test)} obs ({(1-split_ratio)*100:.1f}%) — {test.index[0].strftime(fmt)} → {test.index[-1].strftime(fmt)}")
# print(f"  • Total:  {n} observações | Período geral: {ibov.index[0].strftime(fmt)} → {ibov.index[-1].strftime(fmt)}")

"""# Teste Ljung-Box

"""

# Teste formal de ruído branco (Ljung-Box)
print("TESTE DE RUÍDO BRANCO - LJUNG-BOX")
print("="*60)

retornos_limpos = ibov['Retornos'].dropna()
lb_test = acorr_ljungbox(retornos_limpos, lags=[1, 5, 10, 20], return_df=True)

print(lb_test.round(4))



# Magnitude das correlações
acf_values = acf(retornos_limpos, nlags=20)
pacf_values = pacf(retornos_limpos, nlags=20)


print(f"ACF máxima (excluindo lag 0): {np.max(np.abs(acf_values[1:])):.4f}")
print(f"PACF máxima (excluindo lag 0): {np.max(np.abs(pacf_values[1:])):.4f}")

"""# Modelagem e resultados"""

# 4.4 MODELAGEM E RESULTADOS - VERSÃO COM TABELA CONSOLIDADA

# Divisão dos dados
split_ratio = 0.8
returns = ibov['Retornos'].dropna()
n = len(returns)
split_point = int(n * split_ratio)
train = returns.iloc[:split_point]
test = returns.iloc[split_point:]


print("DIVISÃO DS DADOS")

print(f"Treino: {len(train)} obs ({len(train)/n*100:.1f}%) | {train.index[0].strftime('%d/%m/%Y')} a {train.index[-1].strftime('%d/%m/%Y')}")
print(f"Teste:  {len(test)} obs ({len(test)/n*100:.1f}%) | {test.index[0].strftime('%d/%m/%Y')} a {test.index[-1].strftime('%d/%m/%Y')}")

print("AJUSTANDO MODELOS...")

# Ajustar todos os modelos
modelos = {}
previsoes = {}
resultados = []

# ARIMA(1,0,1)
print("Ajustando ARIMA(1,0,1)...")
arima = ARIMA(train, order=(1,0,1)).fit()
arima_pred = arima.forecast(steps=len(test))
modelos['ARIMA(1,0,1)'] = arima
previsoes['ARIMA(1,0,1)'] = arima_pred

# SARIMA(1,0,1)(1,0,1,5)
print("Ajustando SARIMA(1,0,1)(1,0,1,5)...")
sarima = SARIMAX(train, order=(1,0,1), seasonal_order=(1,0,1,5)).fit(disp=False)
sarima_pred = sarima.forecast(steps=len(test))
modelos['SARIMA'] = sarima
previsoes['SARIMA'] = sarima_pred

# ETS
print("Ajustando ETS(A,N,A) s=5...")
ets = ExponentialSmoothing(train, trend=None, seasonal='add', seasonal_periods=5).fit()
ets_pred = ets.forecast(steps=len(test))
modelos['ETS(s=5)'] = ets
previsoes['ETS(s=5)'] = ets_pred

# Calcular métricas para todos os modelos
for nome, modelo in modelos.items():
    pred = previsoes[nome]

    # Métricas de desempenho
    rmse = np.sqrt(mean_squared_error(test, pred))
    mae = mean_absolute_error(test, pred)
    r2 = r2_score(test, pred)
    aic = modelo.aic
    bic = modelo.bic

    # Diagnóstico dos resíduos
    residuos = modelo.resid if hasattr(modelo, 'resid') else (test - pred)
    jb_stat, jb_p = stats.jarque_bera(residuos)
    lb_test = acorr_ljungbox(residuos, lags=[10], return_df=True)
    lb_p = lb_test['lb_pvalue'].iloc[0]

    resultados.append({
        'Modelo': nome,
        'RMSE': rmse,
        'MAE': mae,
        'R²': r2,
        'AIC': aic,
        'BIC': bic,
        'JB p-valor': jb_p,
        'LB p-valor': lb_p
    })

# Criar DataFrame com resultados
df_resultados = pd.DataFrame(resultados)
df_resultados = df_resultados.set_index('Modelo')

# Exibir tabela principal
print("TABELA DE RESULTADOS - MÉTRICAS DE DESEMPENHO")
print("="*70)
print(df_resultados[['RMSE', 'MAE', 'R²', 'AIC', 'BIC']].round(4).to_string())

# Exibir tabela de diagnóstico
print("TABELA DE DIAGNÓSTICO DOS RESÍDUOS")
print("="*70)
df_diagnostico = df_resultados[['JB p-valor', 'LB p-valor']].copy()
df_diagnostico['Normalidade'] = df_diagnostico['JB p-valor'].apply(lambda x: 'sim' if x > 0.05 else 'nao')
df_diagnostico['Ruído Branco'] = df_diagnostico['LB p-valor'].apply(lambda x: 'sim' if x > 0.05 else 'nao')
print(df_diagnostico[['JB p-valor', 'Normalidade', 'LB p-valor', 'Ruído Branco']].round(4).to_string())

# Identificar melhor modelo por métrica
print("MELHOR MODELO POR MÉTRICA")
print("="*70)

metricas_min = ['RMSE', 'MAE', 'AIC', 'BIC']
metricas_max = ['R²']

resumo_melhores = []
for metrica in metricas_min:
    melhor = df_resultados[metrica].idxmin()
    valor = df_resultados.loc[melhor, metrica]
    resumo_melhores.append({'Métrica': metrica, 'Melhor Modelo': melhor, 'Valor': valor})

for metrica in metricas_max:
    melhor = df_resultados[metrica].idxmax()
    valor = df_resultados.loc[melhor, metrica]
    resumo_melhores.append({'Métrica': metrica, 'Melhor Modelo': melhor, 'Valor': valor})

df_melhores = pd.DataFrame(resumo_melhores)
print(df_melhores.to_string(index=False))

# Contagem de vitórias
vitorias = df_melhores['Melhor Modelo'].value_counts()
print("MODELO VENCEDOR")
print(f"{vitorias.index[0]} venceu em {vitorias.iloc[0]} de 5 métricas")

"""# **Modelo ARIMA**"""

# --- garante split antes de ajustar o ARIMA ---
if 'ibov' not in globals():
    raise RuntimeError("DataFrame 'ibov' não existe. Rode a parte de coleta primeiro.")

# garante coluna de retornos
if 'Returns' not in ibov.columns:
    ibov['Returns'] = np.log(ibov['Close'] / ibov['Close'].shift(1))
ibov = ibov.dropna(subset=['Returns'])

# se não houver train/test definidos, cria agora
if 'train' not in globals() or 'test' not in globals():
    split_ratio = 0.8
    n = len(ibov)
    cut = int(n * split_ratio)
    train = ibov['Returns'].iloc[:cut]
    test  = ibov['Returns'].iloc[cut:]

# --- ARIMA ---
order = (1, 0, 1)
model = ARIMA(train, order=order)
fit = model.fit()

# Forecast alinhado ao índice de teste
fc = pd.Series(fit.forecast(steps=len(test)).values, index=test.index)

# Métricas
rmse = np.sqrt(mean_squared_error(test, fc))
mae  = mean_absolute_error(test, fc)
mape = (np.abs((test - fc) / test.replace(0, np.nan))).dropna().mean() * 100
r2   = r2_score(test, fc)

# Diagnóstico de resíduos
ar = fit.params.get('ar.L1', np.nan)
ma = fit.params.get('ma.L1', np.nan)
lb_p = acorr_ljungbox(fit.resid, lags=[20], return_df=True)['lb_pvalue'].iloc[0]

print(f"[ARIMA] ordem={order} | nobs={fit.nobs} | AIC={fit.aic:.2f} | BIC={fit.bic:.2f}")
print(f"         ar1={ar:.4f} | ma1={ma:.4f}")
print(f"[RESID] Ljung-Box p(20)={lb_p:.4f} → {'ok (sem autocorr.)' if lb_p>0.05 else 'atenção (autocorr.)'}")
print(f"[TEST]  RMSE={rmse:.6f} | MAE={mae:.6f} | MAPE={mape:.2f}% | R²={r2:.4f}")

# Visualização
plt.figure(figsize=(15, 7))
plt.plot(train.index, train, label='Treino', linewidth=1)
plt.plot(test.index, test, label='Teste (real)', linewidth=1.2)
plt.plot(fc.index, fc, '--', label=f'ARIMA{order} (RMSE={rmse:.6f})', linewidth=2)
plt.axvline(test.index[0], color='black', linestyle=':', linewidth=1.5, alpha=0.6, label='Início do teste')
plt.title('ARIMA — Previsão de Retornos do Ibovespa', fontsize=14, fontweight='bold')
plt.xlabel('Data'); plt.ylabel('Retornos logarítmicos')
plt.legend(); plt.grid(alpha=0.3); plt.tight_layout(); plt.show()

"""# **Modelo SARIMA**"""

# SARIMA
assert 'Returns' in ibov.columns and len(train) > 0 and len(test) > 0, "Dados/split inválidos."

# 1) Fit
order = (1,0,1)
sorder = (1,0,1,5)  # semanal (dias úteis ~5)
model_s = SARIMAX(train, order=order, seasonal_order=sorder, enforce_stationarity=False, enforce_invertibility=False)
fit_s = model_s.fit(disp=False)

# 2) Forecast alinhado ao índice de teste
fc_s = pd.Series(fit_s.forecast(steps=len(test)).values, index=test.index)

# 3) Métricas
rmse_s = np.sqrt(mean_squared_error(test, fc_s))
mae_s  = mean_absolute_error(test, fc_s)
mape_s = (np.abs((test - fc_s) / test.replace(0, np.nan))).dropna().mean() * 100
r2_s   = r2_score(test, fc_s)

# 4) Resumo compacto + resíduos
ar1  = fit_s.params.get('ar.L1', np.nan)
ma1  = fit_s.params.get('ma.L1', np.nan)
sar1 = fit_s.params.get('ar.S.L5', np.nan)
sma1 = fit_s.params.get('ma.S.L5', np.nan)
lb_p = acorr_ljungbox(fit_s.resid, lags=[20], return_df=True)['lb_pvalue'].iloc[0]

print(f"[SARIMA] ordem={order} sazonal={sorder} | nobs={fit_s.nobs} | AIC={fit_s.aic:.2f} | BIC={fit_s.bic:.2f}")
print(f"         ar1={ar1:.4f} ma1={ma1:.4f} | sar1={sar1:.4f} sma1={sma1:.4f}")
print(f"[RESID]  Ljung-Box p(20)={lb_p:.4f} → {'ok (sem autocorr.)' if lb_p>0.05 else 'atenção (autocorr.)'}")
print(f"[TEST]   RMSE={rmse_s:.6f} | MAE={mae_s:.6f} | MAPE={mape_s:.2f}% | R²={r2_s:.4f}")

# 5) Visual
plt.figure(figsize=(15,7))
plt.plot(train.index, train, label='Treino', linewidth=1)
plt.plot(test.index,  test,  label='Teste (real)', linewidth=1.2)
plt.plot(fc_s.index,  fc_s,  '--', label=f'SARIMA{order}{sorder} (RMSE={rmse_s:.6f})', linewidth=2)
plt.axvline(test.index[0], color='black', linestyle=':', linewidth=1.5, alpha=0.6, label='Início do teste')
plt.title('SARIMA — Previsão de Retornos do Ibovespa', fontsize=14, fontweight='bold')
plt.xlabel('Data'); plt.ylabel('Retornos logarítmicos')
plt.legend(); plt.grid(alpha=0.3); plt.tight_layout(); plt.show()

"""# **Modelo ETS**"""

# ETS
assert len(train) and len(test), "Splits de treino/teste inválidos."

# 1) Ajuste
ets = ExponentialSmoothing(
    train, trend=None, seasonal='add', seasonal_periods=5  # s≈5 dias úteis (semana)
).fit(optimized=True, use_brute=True)

# 2) Parâmetros e ICs
alpha = ets.model.params.get('smoothing_level', np.nan)
gamma = ets.model.params.get('smoothing_seasonal', np.nan)
try:
    aic_ets, bic_ets = float(ets.aic), float(ets.bic)
except Exception:
    aic_ets, bic_ets = np.nan, np.nan

print(f"[ETS] seasonal=add, s=5 | alpha={alpha:.4f} | gamma={gamma:.4f} | AIC={aic_ets} | BIC={bic_ets}")

# 3) Previsão e métricas
ets_forecast = pd.Series(ets.forecast(steps=len(test)).values, index=test.index)
rmse_ets = np.sqrt(mean_squared_error(test, ets_forecast))
mae_ets  = mean_absolute_error(test, ets_forecast)
mape_ets = (np.abs((test - ets_forecast) / test.replace(0, np.nan))).dropna().mean() * 100
r2_ets   = r2_score(test, ets_forecast)
print(f"[TEST] RMSE={rmse_ets:.6f} | MAE={mae_ets:.6f} | MAPE={mape_ets:.2f}% | R²={r2_ets:.4f}")

# 4) Visualização
plt.figure(figsize=(15,7))
plt.plot(train.index, train, label='Treino', linewidth=1)
plt.plot(test.index,  test,  label='Teste (real)', linewidth=1.2)
plt.plot(ets_forecast.index, ets_forecast, '--', label=f'ETS (s=5) RMSE={rmse_ets:.6f}', linewidth=2)
plt.axvline(test.index[0], color='black', linestyle=':', linewidth=1.5, alpha=0.6, label='Início do teste')
plt.title('ETS (Holt–Winters) — Previsão de Retornos do Ibovespa', fontsize=14, fontweight='bold')
plt.xlabel('Data'); plt.ylabel('Retornos logarítmicos')
plt.grid(alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()

# 5) Erros (teste) e resíduos (treino)
ets_errors    = (test - ets_forecast).values
residuals_ets = pd.Series(ets.resid, index=train.index)

# 6) Diagnóstico compacto dos resíduos (treino)
mu, sd = residuals_ets.mean(), residuals_ets.std()
jb_stat_ets, jb_pvalue_ets = stats.jarque_bera(residuals_ets)
lb_ets = acorr_ljungbox(residuals_ets, lags=[10,20,30], return_df=True)
lb20 = lb_ets.loc[20, 'lb_pvalue'] if 20 in lb_ets.index else np.nan
print(f"[RESID] μ={mu:.6f} | σ={sd:.6f} | skew={stats.skew(residuals_ets):.4f} | kurt={stats.kurtosis(residuals_ets):.4f}")
print(f"        Jarque–Bera p={jb_pvalue_ets:.4f} → {'normal' if jb_pvalue_ets>0.05 else 'não-normal'}")
print(f"        Ljung–Box p(20)={lb20:.4f} → {'sem autocorr.' if lb20>0.05 else 'autocorr.'}")

# Gráficos rápidos de diagnóstico
fig, axes = plt.subplots(1, 3, figsize=(18,5))
axes[0].plot(residuals_ets.index, residuals_ets, linewidth=0.9); axes[0].axhline(0, color='black', linestyle='--', linewidth=1)
axes[0].set_title('Resíduos ETS (Treino)'); axes[0].set_xlabel('Data'); axes[0].set_ylabel('Resíduo'); axes[0].grid(alpha=0.3)

axes[1].hist(residuals_ets, bins=40, density=True, edgecolor='black', alpha=0.6)
x = np.linspace(residuals_ets.min(), residuals_ets.max(), 200)
axes[1].plot(x, stats.norm.pdf(x, mu, sd), linewidth=2, label='Normal teórica')
axes[1].axvline(0, color='black', linestyle='--', linewidth=1)
axes[1].set_title('Distribuição dos Resíduos'); axes[1].set_xlabel('Resíduo'); axes[1].set_ylabel('Densidade')
axes[1].grid(alpha=0.3); axes[1].legend()

stats.probplot(residuals_ets, dist="norm", plot=axes[2])
axes[2].set_title('Q–Q Plot Resíduos ETS'); axes[2].grid(alpha=0.3)
plt.tight_layout(); plt.show()

"""# **Comparação dos modelos**"""

# Comparação ARIMA vs SARIMA vs ETS
models = {
    "ARIMA(1,0,1)": {
        "forecast": pd.Series(fc, index=test.index),
        "rmse": float(rmse),
        "mae":  float(mae),
        "mape": float(mape),
        "r2":   float(r2),
        "aic":  float(fit.aic),
        "bic":  float(fit.bic),
    },
    "SARIMA(1,0,1)(1,0,1,5)": {
        "forecast": pd.Series(fc_s, index=test.index),
        "rmse": float(rmse_s),
        "mae":  float(mae_s),
        "mape": float(mape_s),
        "r2":   float(r2_s),
        "aic":  float(fit_s.aic),
        "bic":  float(fit_s.bic),
    },
    "ETS (s=5)": {
        "forecast": pd.Series(ets_forecast, index=test.index),
        "rmse": float(rmse_ets),
        "mae":  float(mae_ets),
        "mape": float(mape_ets),
        "r2":   float(r2_ets),
        "aic":  float(aic_ets) if 'aic_ets' in globals() else np.nan,
        "bic":  float(bic_ets) if 'bic_ets' in globals() else np.nan,
    },
}

# Erros individuais
for name, d in models.items():
    d["errors"] = (test - d["forecast"]).values

# Tabela de métricas
cols = ["rmse", "mae", "mape", "r2", "aic", "bic"]
df_metrics = pd.DataFrame({m: {k: models[m][k] for k in cols} for m in models}).T
print("[MÉTRICAS]\n", df_metrics.round({"rmse":6,"mae":6,"mape":2,"r2":6,"aic":2,"bic":2}))

# Melhores desempenhos
best_rmse = df_metrics["rmse"].idxmin()
worst_rmse = df_metrics["rmse"].idxmax()
rmse_improv = (df_metrics.loc[worst_rmse,"rmse"] - df_metrics.loc[best_rmse,"rmse"]) / df_metrics.loc[worst_rmse,"rmse"] * 100
print(f"\n[ANÁLISE] Melhor RMSE: {best_rmse} ({df_metrics.loc[best_rmse,'rmse']:.6f}) | ganho vs pior: {rmse_improv:.2f}%")

for crit in ["aic","bic"]:
    if df_metrics[crit].notna().any():
        best_ic = df_metrics[crit].astype(float).idxmin()
        print(f"[INFO] Melhor {crit.upper()}: {best_ic} ({df_metrics.loc[best_ic,crit]:.2f})")

# Estatísticas dos erros
print("\n[ERROS] Estatísticas por modelo")
for name, d in models.items():
    e = d["errors"]
    print(f"  {name:<28} mean={e.mean():.6f} | std={e.std():.6f} | min={e.min():.6f} | max={e.max():.6f}")

# Gráficos de comparação
fig, axes = plt.subplots(3, 1, figsize=(15, 14))

# (1) Previsões vs valores reais
axes[0].plot(test.index, test, label='Valores Reais', linewidth=1.8)
for name, d in models.items():
    axes[0].plot(test.index, d["forecast"], '--', linewidth=1.8, label=f'{name} (RMSE={d["rmse"]:.6f})')
axes[0].set_title('Comparação de Previsões (Teste)', fontsize=14, fontweight='bold')
axes[0].set_xlabel('Data'); axes[0].set_ylabel('Retornos')
axes[0].grid(alpha=0.3); axes[0].legend()

# (2) Erros ao longo do tempo
for name, d in models.items():
    axes[1].plot(test.index, d["errors"], linewidth=1.2, label=f'Erros {name}')
axes[1].axhline(0, color='black', linestyle='--', linewidth=1)
axes[1].set_title('Erros de Previsão ao Longo do Tempo', fontsize=14, fontweight='bold')
axes[1].set_xlabel('Data'); axes[1].set_ylabel('Erro (Real - Previsto)')
axes[1].grid(alpha=0.3); axes[1].legend()

# (3) Distribuição dos erros (bins comuns)
all_errs = np.concatenate([d["errors"] for d in models.values()])
bins = np.linspace(all_errs.min(), all_errs.max(), 50)
for name, d in models.items():
    axes[2].hist(d["errors"], bins=bins, alpha=0.6, label=name, edgecolor='black')
axes[2].axvline(0, color='black', linestyle='--', linewidth=1.8)
axes[2].set_title('Distribuição dos Erros de Previsão', fontsize=14, fontweight='bold')
axes[2].set_xlabel('Erro'); axes[2].set_ylabel('Frequência')
axes[2].grid(alpha=0.3); axes[2].legend()

plt.tight_layout(); plt.show()

# Scatter Real vs Previsto
n_models = len(models)
cols_s = 2 if n_models > 1 else 1
rows_s = int(np.ceil(n_models / cols_s))
fig, axes = plt.subplots(rows_s, cols_s, figsize=(15, 6*rows_s))
axes = np.array(axes).reshape(-1)

for ax, (name, d) in zip(axes, models.items()):
    ax.scatter(test.values, d["forecast"].values, alpha=0.5)
    mn, mx = min(test.min(), d["forecast"].min()), max(test.max(), d["forecast"].max())
    ax.plot([mn, mx], [mn, mx], 'k--', linewidth=2)
    ax.set_title(f'{name}: Real vs Previsto', fontsize=13, fontweight='bold')
    ax.set_xlabel('Real'); ax.set_ylabel('Previsto')
    ax.grid(alpha=0.3)
    ax.text(0.05, 0.95, f'R² = {d["r2"]:.4f}', transform=ax.transAxes,
            va='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

for j in range(len(models), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(); plt.show()

"""# **Diagnóstico do modelo e Estatísticas dos erros de previsão**"""

# Treino
residuals_dict = {}
if 'fit'   in globals(): residuals_dict['ARIMA']  = pd.Series(fit.resid,  index=train.index)
if 'fit_s' in globals(): residuals_dict['SARIMA'] = pd.Series(fit_s.resid, index=train.index)
if 'ets'   in globals(): residuals_dict['ETS']    = pd.Series(ets.resid,   index=train.index)

# Diagnóstico compacto dos resíduos
def diag_residuos(nome, resid: pd.Series, lags=(10,20,30)):
    resid = pd.Series(resid, index=resid.index).dropna()
    m, s  = resid.mean(), resid.std()
    jb_stat, jb_p = stats.jarque_bera(resid)
    lb = acorr_ljungbox(resid, lags=list(lags), return_df=True)

    print(f"[{nome}] μ={m:.6f} | σ={s:.6f} | skew={stats.skew(resid):.4f} | kurt={stats.kurtosis(resid):.4f}")
    print(f"       Jarque–Bera: stat={jb_stat:.4f} | p={jb_p:.4f} → {'normal' if jb_p>0.05 else 'não-normal'}")
    for L in lags:
        p = lb.loc[L, "lb_pvalue"] if L in lb.index else np.nan
        flag = 'sem autocorr.' if (pd.notna(p) and p>0.05) else 'autocorr.'
        print(f"       Ljung–Box lag {L}: p={p:.4f} → {flag}")

    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    # Série temporal
    axes[0,0].plot(resid.index, resid.values, linewidth=0.9)
    axes[0,0].axhline(0, color='black', linestyle='--', linewidth=1)
    axes[0,0].set_title(f'Resíduos {nome} (Treino)'); axes[0,0].set_xlabel('Data'); axes[0,0].set_ylabel('Resíduo'); axes[0,0].grid(alpha=0.3)
    axes[0,0].text(0.02, 0.95, f'μ={m:.6f}\nσ={s:.6f}', transform=axes[0,0].transAxes, va='top',
                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.6))

    # Histograma + normal teórica
    axes[0,1].hist(resid.values, bins=40, density=True, edgecolor='black', alpha=0.6)
    x = np.linspace(resid.min(), resid.max(), 200)
    axes[0,1].plot(x, stats.norm.pdf(x, m, s), linewidth=2, label='Normal teórica')
    axes[0,1].axvline(0, color='black', linestyle='--', linewidth=1)
    axes[0,1].set_title(f'Distribuição dos Resíduos {nome}'); axes[0,1].set_xlabel('Resíduo'); axes[0,1].set_ylabel('Densidade')
    axes[0,1].grid(alpha=0.3); axes[0,1].legend()

    # ACF
    plot_acf(resid.values, lags=40, alpha=0.05, ax=axes[1,0])
    axes[1,0].set_title(f'ACF — Resíduos {nome}'); axes[1,0].set_xlabel('Lags'); axes[1,0].set_ylabel('Autocorr.'); axes[1,0].grid(alpha=0.3)

    # Q–Q plot
    stats.probplot(resid.values, dist="norm", plot=axes[1,1])
    axes[1,1].set_title(f'Q–Q Plot — Resíduos {nome}'); axes[1,1].grid(alpha=0.3)

    plt.tight_layout(); plt.show()

# Executa para todos os modelos disponíveis
for nome, resid in residuals_dict.items():
    diag_residuos(nome, resid)

# Comparação dos erros no TESTE
series_err, labels = [], []
if 'arima_errors'  in globals(): series_err.append(arima_errors);  labels.append('ARIMA')
if 'sarima_errors' in globals(): series_err.append(sarima_errors); labels.append('SARIMA')
if 'ets_errors'    in globals(): series_err.append(ets_errors);    labels.append('ETS')

if series_err:
    # Histograma (bins comuns)
    plt.figure(figsize=(15,6))
    all_vals = np.concatenate([np.asarray(e).ravel() for e in series_err])
    bins = np.linspace(all_vals.min(), all_vals.max(), 50)
    for e, lb in zip(series_err, labels):
        plt.hist(np.asarray(e).ravel(), bins=bins, alpha=0.6, label=lb, edgecolor='black')
    plt.axvline(0, color='black', linestyle='--', linewidth=1.5)
    plt.title('Distribuição dos Erros de Previsão (Teste)'); plt.xlabel('Erro'); plt.ylabel('Frequência')
    plt.grid(alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()

    # Boxplot
    plt.figure(figsize=(8,6))
    plt.boxplot([np.asarray(e).ravel() for e in series_err], labels=labels, patch_artist=True,
                boxprops=dict(facecolor='lightgray', alpha=0.7), medianprops=dict(color='red', linewidth=2))
    plt.axhline(0, color='black', linestyle='--', linewidth=1)
    plt.title('Box Plot — Erros de Previsão (Teste)'); plt.ylabel('Erro')
    plt.grid(alpha=0.3, axis='y'); plt.tight_layout(); plt.show()

print("\n Estatísticas dos erros de previsão")
print("-" * 80)

# Dicionário com os modelos existentes
errors_dict = {
    "ARIMA":  globals().get("arima_errors"),
    "SARIMA": globals().get("sarima_errors"),
    "ETS":    globals().get("ets_errors")
}

# Cria tabela de estatísticas
rows = []
for name, errs in errors_dict.items():
    if errs is None:
        continue
    errs = np.asarray(errs).ravel()
    rows.append({
        "Modelo": name,
        "Erro Médio": errs.mean(),
        "Desvio Padrão": errs.std(),
        "Mínimo": errs.min(),
        "Máximo": errs.max()
    })

df_err = pd.DataFrame(rows)
if not df_err.empty:
    print(df_err.round(6).to_string(index=False))
else:
    print("Nenhum conjunto de erros disponível.")

"""# **Conclusões e recomendações**"""

models = {
    "ARIMA": {
        "rmse": float(rmse),
        "mae":  float(mae),
        "mape": float(mape),
        "r2":   float(r2),
        "aic":  float(fit.aic),
        "bic":  float(fit.bic),
    },
    "SARIMA": {
        "rmse": float(rmse_s),
        "mae":  float(mae_s),
        "mape": float(mape_s),
        "r2":   float(r2_s),
        "aic":  float(fit_s.aic),
        "bic":  float(fit_s.bic),
    }
}

if all(v in globals() for v in ["rmse_ets","mae_ets","mape_ets","r2_ets"]):
    models["ETS"] = {
        "rmse": float(rmse_ets),
        "mae":  float(mae_ets),
        "mape": float(mape_ets),
        "r2":   float(r2_ets),
        "aic":  float(aic_ets) if "aic_ets" in globals() else np.nan,
        "bic":  float(bic_ets) if "bic_ets" in globals() else np.nan,
    }

df = pd.DataFrame(models).T[["rmse","mae","mape","r2","aic","bic"]]
print("\n[Resumo de métricas]")
print(df.round({"rmse":6,"mae":6,"mape":2,"r2":6,"aic":2,"bic":2}))

scores = {m:0 for m in models}
def pontuar(col, maior_melhor=False):
    s = df[col].dropna()
    if s.empty: return None
    best = s.idxmax() if maior_melhor else s.idxmin()
    scores[best] += 1
    return best