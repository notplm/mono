# -*- coding: utf-8 -*-
"""MonoModern.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eMWdilsO7SUZDRd9cRHHfFkD6eCceb0S

# **Configurações**
"""

import yfinance as yf
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from scipy import stats
import warnings
warnings.filterwarnings('ignore')
# ta
import subprocess
import sys
print("Instalando ta.")
subprocess.check_call([sys.executable, "-m", "pip", "install", "ta", "-q"])
print("Biblioteca 'ta' instalada com sucesso no Colab!")

# prophet
print("Instalando Prophet.")
!pip install prophet --upgrade --quiet
!pip install cmdstanpy --quiet
try:
    from prophet import Prophet
    print("Prophet instalado com sucesso!")
except ImportError as e:
    print(f"Erro ao importar Prophet: {e}")
    print("Pode ser necessário reiniciar o kernel do Colab.\nExecute 'Runtime > Restart runtime' e rode novamente.")

# XGBoost
print("Instalando XGBoost.")
!pip install xgboost --quiet
import xgboost as xgb
print("XGBoost instalado com sucesso!")

# TensorFlow/Keras
print("Importando TensorFlow/Keras...")
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

print(f"TensorFlow versão: {tf.__version__}\nBibliotecas carregadas com sucesso!")

"""# **Coleta e preparação dos dados**"""

# Configurações estilo dos gráficos para melhor visualização
# plt.style.use('seaborn-v0_8-darkgrid')
# plt.rcParams['figure.dpi'] = 100
# plt.rcParams['font.size'] = 10

# Download de dados históricos do Ibovespa desde 2010
ibov = yf.download("^BVSP", start="2010-01-01", end="2025-10-01", progress=False)

# print(ibov.info())
# print(ibov.head())

# Calcular retornos logarítmicos (mais adequados para modelagem financeira)
ibov['Retornos'] = np.log(ibov['Close'] / ibov['Close'].shift(1))
ibov = ibov.dropna()
#print(ibov.head())

# Visualizar a série temporal completa
## fig, axes = plt.subplots(2, 1, figsize=(15, 10))

# Gráfico 1: Preço de Fechamento
## axes[0].plot(ibov.index, ibov['Close'], linewidth=1.5, color='navy')
## axes[0].set_title('Série Temporal: Preço de Fechamento do Ibovespa', fontsize=14, fontweight='bold')
## axes[0].set_xlabel('Data', fontsize=12)
## axes[0].set_ylabel('Preço (pontos)', fontsize=12)
## axes[0].grid(alpha=0.3)

# Gráfico 2: Retornos Logarítmicos
## axes[1].plot(ibov.index, ibov['Retornos'], linewidth=0.8, color='darkred', alpha=0.7)
## axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1)
## axes[1].set_title('Série Temporal: Retornos Logarítmicos do Ibovespa', fontsize=14, fontweight='bold')
## axes[1].set_xlabel('Data', fontsize=12)
## axes[1].set_ylabel('Retorno', fontsize=12)
## axes[1].grid(alpha=0.3)

# plt.tight_layout()
## plt.show()

"""# ***Divisão dos dados (treino e teste)***"""

# Divisão treino/teste

split_ratio = 0.8
returns = ibov['Retornos'].dropna()
n = len(returns)
cut = int(n * split_ratio)
train = returns.iloc[:cut]
test = returns.iloc[cut:]

train_df = ibov.iloc[:cut].copy()
test_df = ibov.iloc[cut:].copy()

#print(f"  Treino: {len(train)} obs | {train.index[0].strftime('%d/%m/%Y')} a {train.index[-1].strftime('%d/%m/%Y')}")
#print(f"  Teste:  {len(test)} obs | {test.index[0].strftime('%d/%m/%Y')} a {test.index[-1].strftime('%d/%m/%Y')}")

"""# Engenharia de características"""

# ENGENHARIA DE CARACTERÍSTICAS

if isinstance(ibov.columns, pd.MultiIndex):
    ibov.columns = ibov.columns.get_level_values(0)

def criar_features(df):
    df_feat = df.copy()

    # TARGET - Retorno do próximo dia (t+1)
    df_feat['target'] = df_feat['Retornos'].shift(-1)

    # 1. LAGS DOS RETORNOS
    df_feat['ret_lag1'] = df_feat['Retornos'].shift(1)
    df_feat['ret_lag5'] = df_feat['Retornos'].shift(5)
    df_feat['ret_lag20'] = df_feat['Retornos'].shift(20)

    # 2. INDICADORES TÉCNICOS
    # RSI(14)
    df_feat['rsi'] = ta.momentum.RSIIndicator(
        close=df_feat['Close'], window=14
    ).rsi()

    # MACD(12,26,9)
    macd = ta.trend.MACD(
        close=df_feat['Close'],
        window_slow=26, window_fast=12, window_sign=9
    )
    df_feat['macd'] = macd.macd()
    df_feat['macd_signal'] = macd.macd_signal()
    df_feat['macd_diff'] = macd.macd_diff()

    # Bandas de Bollinger(20,2)
    bb = ta.volatility.BollingerBands(
        close=df_feat['Close'], window=20, window_dev=2
    )
    df_feat['bb_high'] = bb.bollinger_hband()
    df_feat['bb_low'] = bb.bollinger_lband()
    df_feat['bb_mid'] = bb.bollinger_mavg()
    df_feat['bb_pband'] = bb.bollinger_pband()

    # ATR(14)
    df_feat['atr'] = ta.volatility.AverageTrueRange(
        high=df_feat['High'],
        low=df_feat['Low'],
        close=df_feat['Close'],
        window=14
    ).average_true_range()

    # 3. ESTATÍSTICAS MÓVEIS
    # Volatilidade realizada
    df_feat['vol_10d'] = df_feat['Retornos'].rolling(window=10).std()
    df_feat['vol_30d'] = df_feat['Retornos'].rolling(window=30).std()

    # Médias móveis dos retornos
    df_feat['ret_ma5'] = df_feat['Retornos'].rolling(window=5).mean()
    df_feat['ret_ma20'] = df_feat['Retornos'].rolling(window=20).mean()

    # 4. VOLUME
    df_feat['volume_ratio'] = df_feat['Volume'] / df_feat['Volume'].rolling(window=20).mean()

    # 5. FEATURES TEMPORAIS (codificação cíclica)
    df_feat['weekday_sin'] = np.sin(2 * np.pi * df_feat.index.dayofweek / 7)
    df_feat['weekday_cos'] = np.cos(2 * np.pi * df_feat.index.dayofweek / 7)
    df_feat['month_sin'] = np.sin(2 * np.pi * df_feat.index.month / 12)
    df_feat['month_cos'] = np.cos(2 * np.pi * df_feat.index.month / 12)
    df_feat['quarter'] = df_feat.index.quarter

    return df_feat

# Aplicar engenharia de features
ibov_ml = criar_features(ibov)

# Estatísticas das features criadas
features_criadas = [col for col in ibov_ml.columns if col not in ibov.columns]
#print(f"\nFeatures criadas: {len(features_criadas)}")
#print(f"Total de colunas: {len(ibov_ml.columns)}")

# Remover observações com NaN
ibov_ml = ibov_ml.dropna()

# Análise de correlação com target
print(f"\nTop 10 features exceto target")
correlations = ibov_ml.corr()['target'].abs().sort_values(ascending=False)
for i, (feat, corr) in enumerate(correlations.head(11).items(), 0):
    if i == 0:  # Skip alvo
        continue
    print(f"{i:2d}. {feat:<15} | {corr:.4f}")

# Separar features e target
feature_cols = [col for col in ibov_ml.columns if col not in ['target', 'Open', 'High', 'Low', 'Close', 'Volume', 'Retornos']]
print(f"\nTotal de features para modelagem: {len(feature_cols)}")

# Divisão temporal mantendo consistência com modelos clássicos
split_ratio = 0.8
n = len(ibov_ml)
split_point = int(n * split_ratio)

train_ml = ibov_ml.iloc[:split_point]
test_ml = ibov_ml.iloc[split_point:]

# Preparar dados para modelagem (XGBoost e LSTM)
X_train = train_ml[feature_cols]
y_train = train_ml['target']
X_test = test_ml[feature_cols]
y_test = test_ml['target']

"""# Prophet"""

# PROPHET
# Preparar dados no formato do Prophet
# Prophet requer colunas 'ds' (data) e 'y' (valor a prever)
train_prophet = pd.DataFrame({
    'ds': train.index,
    'y': train.values
})

test_prophet = pd.DataFrame({
    'ds': test.index,
    'y': test.values
})

#print(f"Dados de treino: {len(train_prophet)} observações")
#print(f"Dados de teste: {len(test_prophet)} observações")

# Configurar e treinar o modelo

model_prophet = Prophet(
    changepoint_prior_scale=0.05,
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False,
    interval_width=0.95
)

# Treinar
#import logging
#logging.getLogger('prophet').setLevel(logging.WARNING)
model_prophet.fit(train_prophet)
#print("Modelo treinado com sucesso!")

# Fazer previsões
future = model_prophet.make_future_dataframe(periods=len(test_prophet), freq='B')
forecast = model_prophet.predict(future)

# Extrair previsões apenas para o período de teste
prophet_pred = forecast.iloc[-len(test_prophet):][['ds', 'yhat', 'yhat_lower', 'yhat_upper']]
prophet_pred.index = test_prophet['ds'].values
prophet_pred_values = prophet_pred['yhat'].values

# Calcular métricas

rmse_prophet = np.sqrt(mean_squared_error(test.values, prophet_pred_values))
mae_prophet = mean_absolute_error(test.values, prophet_pred_values)
mape_prophet = np.mean(np.abs((test.values - prophet_pred_values) / test.values[test.values != 0])) * 100
r2_prophet = r2_score(test.values, prophet_pred_values)

print(f"RMSE: {rmse_prophet:.6f}")
print(f"MAE:  {mae_prophet:.6f}")
print(f"MAPE: {mape_prophet:.2f}%")
print(f"R²:   {r2_prophet:.6f}")

# Análise de componentes
# Verificar changepoints detectados
if hasattr(model_prophet, 'changepoints') and len(model_prophet.changepoints) > 0:
    n_changepoints = len(model_prophet.changepoints)
    print(f"Changepoints detectados: {n_changepoints}")
    print(f"Primeiro changepoint: {model_prophet.changepoints.iloc[0].strftime('%d/%m/%Y')}")
    print(f"Último changepoint: {model_prophet.changepoints.iloc[-1].strftime('%d/%m/%Y')}")
else:
    print("Nenhum changepoint detectado ou disponível")

# Visualizar previsões
plt.figure(figsize=(15, 6))
plt.plot(test.index, test.values, label='Real', linewidth=1, alpha=0.7)
plt.plot(test.index, prophet_pred_values, '--', label=f'Prophet (RMSE={rmse_prophet:.6f})', linewidth=1)
plt.fill_between(test.index,
                 prophet_pred['yhat_lower'].values,
                 prophet_pred['yhat_upper'].values,
                 alpha=0.1, label='Intervalo 95%')
plt.title('Prophet - Previsões vs Valores Reais (Teste)', fontsize=14, fontweight='bold')
plt.xlabel('Data')
plt.ylabel('Retornos')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# Decomposição dos componentes (se disponível)
try:
    print("\nDecomposição da série temporal:")
    fig = model_prophet.plot_components(forecast)
    plt.suptitle('Componentes do Modelo Prophet', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.show()
except Exception as e:
    print(f"Não foi possível plotar componentes: {e}")

# Armazenar resultados
resultados_prophet = {
    'modelo': 'Prophet',
    'rmse': rmse_prophet,
    'mae': mae_prophet,
    'mape': mape_prophet,
    'r2': r2_prophet,
    'previsoes': prophet_pred_values
}

"""# XGBoost"""

# XGBOOST
# Verificar dados disponíveis
print(f"\nDados para modelagem:")
print(f"X_train: {X_train.shape} | y_train: {y_train.shape}")
print(f"X_test: {X_test.shape} | y_test: {y_test.shape}")

# Configurar XGBoost conforme metodologia
# criar modelo
model_xgb = xgb.XGBRegressor(
    n_estimators=200,
    max_depth=7,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    objective='reg:squarederror',
    n_jobs=-1
)

# treinar modelo
model_xgb.fit(X_train, y_train)

#print(f"Modelo treinado! Parâmetros utilizados: n_estimators={model_xgb.n_estimators}")

# Fazer previsões
xgb_pred = model_xgb.predict(X_test)

# Calcular métricas
rmse_xgb = np.sqrt(mean_squared_error(y_test, xgb_pred))
mae_xgb = mean_absolute_error(y_test, xgb_pred)

# MAPE com proteção contra divisão por zero
mask = y_test != 0
if mask.sum() > 0:
    mape_xgb = np.mean(np.abs((y_test[mask] - xgb_pred[mask]) / y_test[mask])) * 100
else:
    mape_xgb = 0.0

r2_xgb = r2_score(y_test, xgb_pred)

print(f"RMSE: {rmse_xgb:.6f}")
print(f"MAE:  {mae_xgb:.6f}")
print(f"MAPE: {mape_xgb:.2f}%")
print(f"R²:   {r2_xgb:.6f}")

# Análise de importância das features
print("Top 10 Features mais importantes:")

feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model_xgb.feature_importances_
}).sort_values('importance', ascending=False)

for idx, (i, row) in enumerate(feature_importance.head(10).iterrows(), 1):
    print(f"{idx:2d}. {row['feature']:<15} | {row['importance']:.4f}")

# Visualizar previsões
plt.figure(figsize=(15, 6))
plt.plot(y_test.index, y_test.values, label='Real', linewidth=1, alpha=0.7)
plt.plot(y_test.index, xgb_pred, '--', label=f'XGBoost (RMSE={rmse_xgb:.6f})', linewidth=1)
plt.title('XGBoost - Previsões vs Valores Reais (Teste)', fontsize=14, fontweight='bold')
plt.xlabel('Data')
plt.ylabel('Retornos')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# Gráfico de importância das features
plt.figure(figsize=(10, 8))
top_features = feature_importance.head(15)
plt.barh(range(len(top_features)), top_features['importance'].values)
plt.yticks(range(len(top_features)), top_features['feature'].values)
plt.xlabel('Importância')
plt.title('XGBoost - Importância das Features (Top 15)', fontsize=14, fontweight='bold')
plt.grid(alpha=0.3, axis='x')
plt.tight_layout()
plt.show()

# Análise de resíduos
residuos_xgb = y_test.values - xgb_pred

fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Histograma dos resíduos
axes[0].hist(residuos_xgb, bins=50, density=True, alpha=0.7, edgecolor='black')
axes[0].axvline(0, color='red', linestyle='--', linewidth=1)
axes[0].set_title('XGBoost - Distribuição dos Resíduos')
axes[0].set_xlabel('Resíduo')
axes[0].set_ylabel('Densidade')
axes[0].grid(alpha=0.3)

# Q-Q plot
from scipy import stats
stats.probplot(residuos_xgb, dist="norm", plot=axes[1])
axes[1].set_title('XGBoost - Q-Q Plot dos Resíduos')
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()

# Comparação com modelos anteriores
print("\nComparação XGBoost vs Prophet:")
print("-"*40)
if 'rmse_prophet' in globals():
    print(f"Prophet - RMSE: {rmse_prophet:.6f} | R²: {r2_prophet:.6f}")
print(f"XGBoost - RMSE: {rmse_xgb:.6f} | R²: {r2_xgb:.6f}")

# Armazenar resultados
resultados_xgb = {
    'modelo': 'XGBoost',
    'rmse': rmse_xgb,
    'mae': mae_xgb,
    'mape': mape_xgb,
    'r2': r2_xgb,
    'previsoes': xgb_pred,
    'feature_importance': feature_importance
}

# # ===============================================
# # 4.4.4 LSTM - INSTALAÇÃO E PREPARAÇÃO
# # ===============================================

# print("\n" + "="*70)
# print("4.4.4 Modelo LSTM (Long Short-Term Memory)")
# print("-" * 40)

# # Importar bibliotecas necessárias
# import numpy as np
# import pandas as pd
# from sklearn.preprocessing import StandardScaler, MinMaxScaler
# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
# import matplotlib.pyplot as plt
# import warnings
# warnings.filterwarnings('ignore')

# # TensorFlow/Keras
# print("Importando TensorFlow/Keras...")
# import tensorflow as tf
# from tensorflow import keras
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import LSTM, Dense, Dropout
# from tensorflow.keras.callbacks import EarlyStopping

# print(f"TensorFlow versão: {tf.__version__}")
# print("Bibliotecas carregadas com sucesso!")

"""# LSTM"""

#LSTM
# Parâmetros conforme metodologia
SEQUENCE_LENGTH = 60  # Janela de 60 dias conforme metodologia
LSTM_UNITS_1 = 128    # Primeira camada
LSTM_UNITS_2 = 64     # Segunda camada
DROPOUT_RATE = 0.2
BATCH_SIZE = 32
EPOCHS = 100

# 1. NORMALIZAÇÃO DOS DADOS
# Normalizar features (StandardScaler)
scaler_X = StandardScaler()
X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

# Normalizar target (MinMaxScaler conforme metodologia)
scaler_y = MinMaxScaler()
y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()
y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()

# 2. CRIAR SEQUÊNCIAS TEMPORAIS
def create_sequences(X, y, sequence_length):
    X_seq = []
    y_seq = []

    for i in range(sequence_length, len(X)):
        X_seq.append(X[i-sequence_length:i])
        y_seq.append(y[i])

    return np.array(X_seq), np.array(y_seq)

# Criar sequências para treino
X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, SEQUENCE_LENGTH)
#print(f"  Treino: {X_train_seq.shape} -> {y_train_seq.shape}")

# Criar sequências para teste
X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, SEQUENCE_LENGTH)
#print(f"  Teste: {X_test_seq.shape} -> {y_test_seq.shape}")

# 3. CONSTRUIR MODELO LSTM
model_lstm = Sequential([
    # Primeira camada LSTM
    LSTM(LSTM_UNITS_1, return_sequences=True, input_shape=(SEQUENCE_LENGTH, X_train.shape[1])),
    Dropout(DROPOUT_RATE),

    # Segunda camada LSTM
    LSTM(LSTM_UNITS_2, return_sequences=False),
    Dropout(DROPOUT_RATE),

    # Camada de saída
    Dense(1)
])

# Compilar modelo
model_lstm.compile(
    optimizer='adam',
    loss='mse',
    metrics=['mae']
)

#print("Arquitetura do modelo:")
print(model_lstm.summary())

# 4. TREINAR MODELO
# Early stopping para evitar overfitting
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True,
    verbose=0
)

# Treinar
history = model_lstm.fit(
    X_train_seq, y_train_seq,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    validation_split=0.1,
    callbacks=[early_stopping],
    verbose=0
)

print(f"Treinamento concluído em {len(history.history['loss'])} épocas")

# 5. FAZER PREVISÕES

# Prever
lstm_pred_scaled = model_lstm.predict(X_test_seq, verbose=0)

# Reverter normalização
lstm_pred = scaler_y.inverse_transform(lstm_pred_scaled).flatten()
y_test_lstm = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1)).flatten()

# 6. CALCULAR MÉTRICAS
print("Métricas de desempenho:")
print("-"*40)

rmse_lstm = np.sqrt(mean_squared_error(y_test_lstm, lstm_pred))
mae_lstm = mean_absolute_error(y_test_lstm, lstm_pred)

# MAPE com proteção
mask = y_test_lstm != 0
if mask.sum() > 0:
    mape_lstm = np.mean(np.abs((y_test_lstm[mask] - lstm_pred[mask]) / y_test_lstm[mask])) * 100
else:
    mape_lstm = 0.0

r2_lstm = r2_score(y_test_lstm, lstm_pred)

print(f"RMSE: {rmse_lstm:.6f}")
print(f"MAE:  {mae_lstm:.6f}")
print(f"MAPE: {mape_lstm:.2f}%")
print(f"R²:   {r2_lstm:.6f}")

# 7. VISUALIZAÇÕES
# Curvas de aprendizado
plt.figure(figsize=(15, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Treino')
plt.plot(history.history['val_loss'], label='Validação')
plt.title('LSTM - Evolução da Loss')
plt.xlabel('Época')
plt.ylabel('Loss (MSE)')
plt.legend()
plt.grid(alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(history.history['mae'], label='Treino')
plt.plot(history.history['val_mae'], label='Validação')
plt.title('LSTM - Evolução do MAE')
plt.xlabel('Época')
plt.ylabel('MAE')
plt.legend()
plt.grid(alpha=0.3)

plt.tight_layout()
plt.show()

# Previsões vs Real
# Ajustar índices para visualização (devido às sequências)
test_dates = y_test.index[SEQUENCE_LENGTH:]

plt.figure(figsize=(15, 6))
plt.plot(test_dates, y_test_lstm, label='Real', linewidth=1, alpha=0.7)
plt.plot(test_dates, lstm_pred, '--', label=f'LSTM (RMSE={rmse_lstm:.6f})', linewidth=1)
plt.title('LSTM - Previsões vs Valores Reais (Teste)', fontsize=14, fontweight='bold')
plt.xlabel('Data')
plt.ylabel('Retornos')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

# Análise de resíduos
residuos_lstm = y_test_lstm - lstm_pred

fig, axes = plt.subplots(1, 2, figsize=(15, 5))

axes[0].hist(residuos_lstm, bins=50, density=True, alpha=0.7, edgecolor='black')
axes[0].axvline(0, color='red', linestyle='--', linewidth=1)
axes[0].set_title('LSTM - Distribuição dos Resíduos')
axes[0].set_xlabel('Resíduo')
axes[0].set_ylabel('Densidade')
axes[0].grid(alpha=0.3)

from scipy import stats
stats.probplot(residuos_lstm, dist="norm", plot=axes[1])
axes[1].set_title('LSTM - Q-Q Plot dos Resíduos')
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()

# Armazenar resultados
resultados_lstm = {
    'modelo': 'LSTM',
    'rmse': rmse_lstm,
    'mae': mae_lstm,
    'mape': mape_lstm,
    'r2': r2_lstm,
    'previsoes': lstm_pred,
    'epochs': len(history.history['loss'])
}

# Comparação com modelos anteriores
print("\nComparação LSTM vs outros modelos:")
print("-"*40)
if 'rmse_prophet' in globals():
    print(f"Prophet - RMSE: {rmse_prophet:.6f} | R²: {r2_prophet:.6f}")
if 'rmse_xgb' in globals():
    print(f"XGBoost - RMSE: {rmse_xgb:.6f} | R²: {r2_xgb:.6f}")
print(f"LSTM    - RMSE: {rmse_lstm:.6f} | R²: {r2_lstm:.6f}")

"""# Comparação final"""

# PREPARAÇÃO PARA COMPARAÇÃO FINAL
# Compilar resultados se disponíveis
modelos_resultados = []

# Modelos clássicos (se disponíveis nos globals)
if 'rmse' in globals() and 'r2' in globals():
    modelos_resultados.append(['ARIMA(1,0,1)', rmse, mae, r2])

if 'rmse_s' in globals() and 'r2_s' in globals():
    modelos_resultados.append(['SARIMA', rmse_s, mae_s, r2_s])

if 'rmse_ets' in globals() and 'r2_ets' in globals():
    modelos_resultados.append(['ETS(s=5)', rmse_ets, mae_ets, r2_ets])

# Modelos modernos
if 'rmse_prophet' in globals():
    modelos_resultados.append(['Prophet', rmse_prophet, mae_prophet, r2_prophet])

if 'rmse_xgb' in globals():
    modelos_resultados.append(['XGBoost', rmse_xgb, mae_xgb, r2_xgb])

if 'rmse_lstm' in globals():
    modelos_resultados.append(['LSTM', rmse_lstm, mae_lstm, r2_lstm])

# Criar DataFrame de comparação
if modelos_resultados:
    df_comparacao = pd.DataFrame(modelos_resultados, columns=['Modelo', 'RMSE', 'MAE', 'R²'])
    df_comparacao = df_comparacao.sort_values('RMSE')

    print("\nTabela Comparativa - Métricas de Desempenho:")
    print("-"*50)
    print(df_comparacao.to_string(index=False))

    print("\n" + "-"*50)
    print(f"Melhor RMSE: {df_comparacao.iloc[0]['Modelo']} ({df_comparacao.iloc[0]['RMSE']:.6f})")
    print(f"Melhor R²: {df_comparacao.loc[df_comparacao['R²'].idxmax()]['Modelo']} ({df_comparacao['R²'].max():.6f})")

"""# Comparação completa"""

# ANÁLISE COMPARATIVA COMPLETA

# Criar DataFrame comparativo completo
# Nota: Incluindo apenas os modelos modernos disponíveis no contexto atual
modelos_data = {
    'Modelo': ['Prophet', 'XGBoost', 'LSTM'],
    'RMSE': [rmse_prophet, rmse_xgb, rmse_lstm],
    'MAE': [mae_prophet, mae_xgb, mae_lstm],
    'MAPE': [mape_prophet, mape_xgb, mape_lstm],
    'R²': [r2_prophet, r2_xgb, r2_lstm]
}

df_comparacao = pd.DataFrame(modelos_data)

print("\n1. TABELA COMPARATIVA COMPLETA")

print(df_comparacao.to_string(index=False))

# Estatísticas descritivas
print("\n2. ESTATÍSTICAS DAS MÉTRICAS")

stats = df_comparacao[['RMSE', 'MAE', 'R²']].describe()
print(stats.round(6))

# Ranking por métrica
print("\n3. RANKING DOS MODELOS")


for metrica in ['RMSE', 'MAE']:
    best = df_comparacao.loc[df_comparacao[metrica].idxmin()]
    print(f"Melhor {metrica}: {best['Modelo']} ({best[metrica]:.6f})")

best_r2 = df_comparacao.loc[df_comparacao['R²'].idxmax()]
print(f"Melhor R²: {best_r2['Modelo']} ({best_r2['R²']:.6f})")

# Visualizações comparativas
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 1. Comparação de RMSE
axes[0, 0].bar(df_comparacao['Modelo'], df_comparacao['RMSE'], color=['#2E86AB', '#A23B72', '#F18F01'])
axes[0, 0].set_title('Comparação de RMSE', fontsize=14, fontweight='bold')
axes[0, 0].set_ylabel('RMSE')
axes[0, 0].grid(alpha=0.3, axis='y')
axes[0, 0].set_ylim(0.010, 0.011)

# 2. Comparação de MAE
axes[0, 1].bar(df_comparacao['Modelo'], df_comparacao['MAE'], color=['#2E86AB', '#A23B72', '#F18F01'])
axes[0, 1].set_title('Comparação de MAE', fontsize=14, fontweight='bold')
axes[0, 1].set_ylabel('MAE')
axes[0, 1].grid(alpha=0.3, axis='y')

# 3. Comparação de R²
axes[1, 0].bar(df_comparacao['Modelo'], df_comparacao['R²'], color=['#2E86AB', '#A23B72', '#F18F01'])
axes[1, 0].set_title('Comparação de R²', fontsize=14, fontweight='bold')
axes[1, 0].set_ylabel('R²')
axes[1, 0].axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)
axes[1, 0].grid(alpha=0.3, axis='y')

# 4. Heatmap de métricas normalizadas
# Normalizar métricas para comparação (0-1)
df_norm = df_comparacao[['RMSE', 'MAE', 'R²']].copy()
df_norm['RMSE'] = 1 - (df_norm['RMSE'] - df_norm['RMSE'].min()) / (df_norm['RMSE'].max() - df_norm['RMSE'].min())
df_norm['MAE'] = 1 - (df_norm['MAE'] - df_norm['MAE'].min()) / (df_norm['MAE'].max() - df_norm['MAE'].min())
df_norm['R²'] = (df_norm['R²'] - df_norm['R²'].min()) / (df_norm['R²'].max() - df_norm['R²'].min())

sns.heatmap(df_norm.T,
            xticklabels=df_comparacao['Modelo'],
            yticklabels=['RMSE', 'MAE', 'R²'],
            annot=True, fmt='.3f', cmap='RdYlGn',
            ax=axes[1, 1], vmin=0, vmax=1)
axes[1, 1].set_title('Desempenho Normalizado (0=pior, 1=melhor)', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.show()

# Análise de consistência entre métricas
print("\n4. ANÁLISE DE CONSISTÊNCIA")


# Correlação entre rankings
rank_rmse = df_comparacao['RMSE'].rank()
rank_mae = df_comparacao['MAE'].rank()
rank_r2 = df_comparacao['R²'].rank(ascending=False)

print(f"Correlação entre rankings RMSE e MAE: {rank_rmse.corr(rank_mae):.3f}")
print(f"Correlação entre rankings RMSE e R²: {rank_rmse.corr(rank_r2):.3f}")

# Comparação de previsões (se disponíveis)
if all(x in globals() for x in ['prophet_pred_values', 'xgb_pred', 'lstm_pred']):
    print("\n5. ESTATÍSTICAS DAS PREVISÕES")


    # Ajustar tamanhos (LSTM tem menos observações)
    min_len = min(len(prophet_pred_values), len(xgb_pred), len(lstm_pred))

    pred_stats = pd.DataFrame({
        'Prophet': prophet_pred_values[:min_len],
        'XGBoost': xgb_pred[:min_len],
        'LSTM': lstm_pred[:min_len]
    }).describe()

    print(pred_stats.round(6))

    # Correlação entre previsões
    print("\n6. CORRELAÇÃO ENTRE PREVISÕES")

    corr_matrix = pd.DataFrame({
        'Prophet': prophet_pred_values[:min_len],
        'XGBoost': xgb_pred[:min_len],
        'LSTM': lstm_pred[:min_len]
    }).corr()
    print(corr_matrix.round(3))
